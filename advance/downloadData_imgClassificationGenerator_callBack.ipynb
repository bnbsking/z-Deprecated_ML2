{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wooden-apple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2939 images belonging to 5 classes.\n",
      "Found 731 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataDir = tf.keras.utils.get_file('flower_photos',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "    untar=True) # download data # (str) C:\\Users\\James\\.keras\\datasets\\flower_photos \n",
    "\n",
    "initGenerator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=.20)\n",
    "# more args # rotation_range (int) # horizontal_flip (bool) # vertical_flip (bool)\n",
    "trainGenerator = initGenerator.flow_from_directory(dataDir, target_size=(64,64), batch_size=32, \\\n",
    "    shuffle=False, subset=\"training\", interpolation=\"bilinear\")\n",
    "valGenerator = initGenerator.flow_from_directory(dataDir, target_size=(64,64), batch_size=32, \\\n",
    "    shuffle=False, subset=\"validation\", interpolation=\"bilinear\")\n",
    "# classes auto determined by folders # interpolation image resize method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "based-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_3 (Dropout)          (None, 64, 64, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                196624    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 196,709\n",
      "Trainable params: 196,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(64,64,3)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(16),\n",
    "    tf.keras.layers.Dense(trainGenerator.num_classes)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "agricultural-metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "  metrics=['accuracy'],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "statistical-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "92/92 [==============================] - 8s 90ms/step - loss: 7.5903 - accuracy: 0.2521 - val_loss: 7.3928 - val_accuracy: 0.2449\n",
      "Epoch 2/5\n",
      "92/92 [==============================] - 10s 111ms/step - loss: 7.3389 - accuracy: 0.2446 - val_loss: 7.2850 - val_accuracy: 0.2449\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(trainGenerator, validation_data=valGenerator, epochs=5, callbacks=[tf.keras.\\\n",
    "    callbacks.EarlyStopping(monitor='loss', patience=1, min_delta=1, restore_best_weights=True)], \\\n",
    "    ).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "armed-netscape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  185.90547,   412.56293,  -637.04425,  -742.4653 , -2953.941  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "#img = cv2.imread(r\"C:\\Users\\James\\.keras\\datasets\\flower_photos\\daisy\\21652746_cc379e0eea_m.jpg\")\n",
    "img = cv2.imread(r\"C:\\Users\\James\\.keras\\datasets\\flower_photos\\daisy\\15207766_fc2f1d692c_n.jpg\")\n",
    "#img = cv2.imread(r\"C:\\Users\\James\\.keras\\datasets\\flower_photos\\roses\\12240303_80d87f77a3_n.jpg\")\n",
    "img = cv2.resize(img, (64,64)) / 255\n",
    "\n",
    "model.predict( img.reshape(1,64,64,3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-snapshot",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
